# Mikel BrostrÃ¶m ğŸ”¥ Yolo Tracking ğŸ§¾ AGPL-3.0 license

import argparse
import cv2
import numpy as np
from functools import partial
from pathlib import Path

import torch

from boxmot import TRACKERS # TRACKERS = ['bytetrack', 'botsort', 'strongsort', 'ocsort', 'deepocsort', 'hybridsort', 'imprassoc']
from boxmot.tracker_zoo import create_tracker
from boxmot.utils import ROOT, WEIGHTS, TRACKER_CONFIGS
from boxmot.utils.checks import RequirementsChecker
from tracking.detectors import get_yolo_inferer

# checker = RequirementsChecker()
# checker.check_packages(('ultralytics @ git+https://github.com/mikel-brostrom/ultralytics.git', ))  # install

from ultralytics import YOLO
from ultralytics.utils.plotting import Annotator, colors
from ultralytics.data.utils import VID_FORMATS
from ultralytics.utils.plotting import save_one_box

# åœ¨é¢„æµ‹å¼€å§‹æ—¶åˆå§‹åŒ–è·Ÿè¸ªå™¨
def on_predict_start(predictor, persist=False):
    """
    Initialize trackers for object tracking during prediction.

    Args:
        predictor (object): The predictor object to initialize trackers for. # è¦åˆå§‹trackersçš„predictor
        persist (bool, optional): Whether to persist the trackers if they already exist. Defaults to False. # æ˜¯å¦æŒç»­ä¿å­˜å·²ç»å­˜åœ¨çš„è·Ÿè¸ªå™¨
    """
    print('\n on_predict_start----\n')
    assert predictor.custom_args.tracking_method in TRACKERS, \
        f"'{predictor.custom_args.tracking_method}' is not supported. Supported ones are {TRACKERS}"

    tracking_config = TRACKER_CONFIGS / (predictor.custom_args.tracking_method + '.yaml')   # ROOT/boxmot/configs/XXX.ymal
    trackers = [] # è·Ÿè¸ªå™¨åˆ—è¡¨
    for i in range(predictor.dataset.bs):  #    # predictor.dataset.bs default is 1  ?
        print('predictor.dataset.bs is {}\n'.format(predictor.dataset.bs))
        # æ ¹æ®batchSizeï¼Œåˆ›å»ºè·Ÿè¸ªå™¨
        # reate_tracker(tracker_type, tracker_config=None, reid_weights=None, device=None, half=None, per_class=None, evolve_param_dict=None)
        tracker = create_tracker(
            predictor.custom_args.tracking_method,  # tracker_type,å®šä¹‰äº†å®ä¾‹åŒ–çš„å“ªä¸€ç§è·Ÿè¸ªå™¨ å¦‚StrongSORTã€Deepsort
            tracking_config,  # è®¾ç½®å„ä¸ªè·Ÿè¸ªå™¨çš„è¶…å‚æ•°
            predictor.custom_args.reid_model,  # å¯¹åº”å‡½æ•°æ¥æ”¶å‚æ•°ï¼šreid_weights
            predictor.device,
            predictor.custom_args.half,
            predictor.custom_args.per_class
        )
        # motion only modeles do not have
        # æ£€æŸ¥ tracker å¯¹è±¡æ˜¯å¦å…·æœ‰ model å±æ€§ï¼ˆå³è·Ÿè¸ªå™¨ä¸­æ˜¯å¦åŒ…å«æ¨¡å‹ï¼‰ï¼Œå¦‚æœæœ‰ï¼Œåˆ™è°ƒç”¨ tracker.model.warmup() å¯¹æ¨¡å‹è¿›è¡Œçƒ­èº«ï¼Œè¿™é€šå¸¸æ˜¯ä¸ºäº†åœ¨å®é™…ä½¿ç”¨å‰å°†æ¨¡å‹åŠ è½½åˆ° GPU ä¸Šï¼Œä»¥å‡å°‘æ¨ç†æ—¶çš„å»¶è¿Ÿã€‚
        if hasattr(tracker, 'model'):
            tracker.model.warmup()
        trackers.append(tracker)

    predictor.trackers = trackers


@torch.no_grad()
def run(args):
    
    ul_models = ['yolov8', 'yolov9', 'yolov10', 'rtdetr', 'sam']

    yolo = YOLO(
        args.yolo_model if any(yolo in str(args.yolo_model) for yolo in ul_models) else 'yolov8n.pt',
    )



    results = yolo.track(
        source=args.source,
        conf=args.conf,
        iou=args.iou,
        agnostic_nms=args.agnostic_nms,
        show=False,
        stream=True,    # default is True
        device=args.device,
        show_conf=args.show_conf,
        save_txt=args.save_txt,
        show_labels=args.show_labels,
        save=args.save,
        verbose=args.verbose,
        exist_ok=args.exist_ok,
        project=args.project,
        name=args.name,
        classes=args.classes,
        imgsz=args.imgsz,
        vid_stride=args.vid_stride,
        line_width=args.line_width
    )

    # å‘æ¨¡å‹ä¸­æ·»åŠ å›è°ƒå‡½æ•°ã€‚å›è°ƒå‡½æ•°ä¼šåœ¨ç‰¹å®šçš„äº‹ä»¶æˆ–æ—¶æœºè¢«è§¦å‘ï¼Œæ¯”å¦‚åœ¨é¢„æµ‹å¼€å§‹æ—¶ã€è®­ç»ƒç»“æŸæ—¶ç­‰ã€‚
    # 'on_predict_start'æ˜¯å›è°ƒå‡½æ•°è§¦å‘çš„æ—¶æœºï¼Œå³åœ¨é¢„æµ‹å¼€å§‹æ—¶æ‰§è¡Œã€‚æ­¤æ—¶ï¼ŒYOLO æ¨¡å‹è¿˜æ²¡æœ‰çœŸæ­£å¼€å§‹å¤„ç†è¾“å…¥æ•°æ®ï¼Œåªæ˜¯å‡†å¤‡å¥½è¿›è¡Œé¢„æµ‹ã€‚
    # [partialå¯¹åŸå‡½æ•°çš„æŸäº›å‚æ•°è¿›è¡Œé¢„è®¾ï¼Œè¿”å›ä¸€ä¸ªæ–°çš„å‡½æ•°ã€‚]  å³ï¼šæ¯æ¬¡è§¦å‘ on_predict_start äº‹ä»¶æ—¶ï¼Œéƒ½ä¼šè°ƒç”¨è¿™ä¸ªéƒ¨åˆ†åº”ç”¨çš„ on_predict_start å‡½æ•°ï¼Œå¹¶ä¸” persist å‚æ•°çš„å€¼å§‹ç»ˆä¸º Trueã€‚
    yolo.add_callback('on_predict_start', partial(on_predict_start, persist=True))

    if not any(yolo in str(args.yolo_model) for yolo in ul_models):
        # replace yolov8 model
        m = get_yolo_inferer(args.yolo_model)
        model = m(
            model=args.yolo_model,
            device=yolo.predictor.device,
            args=yolo.predictor.args
        )
        yolo.predictor.model = model

    # store custom args in predictor
    yolo.predictor.custom_args = args
    print("self.predictor is {}:".format(yolo.predictor))

    # å¯¹ç»“æœè¿›è¡Œä¸€äº›å¤„ç†
    print(results)
    print("éå†results\n")
    for i,r in enumerate(results):    # æ¯å¸§äº§ç”Ÿä¸€ä¸ªresults
        print("éå†ç¬¬{}ä¸ª".format(i))
        #æŠŠç»“æœ()ç”»åœ¨å›¾åƒä¸Šã€‚
        img = yolo.predictor.trackers[0].plot_results(r.orig_img, args.show_trajectories)
        # img = yolo.predictor.trackers[0].plot_results(r.orig_img, args.show_trajectories)

        # if args.show is True:
        #     print("args.show is True")
        #     cv2.imshow('BoxMOT', img)
        #     key = cv2.waitKey(1) & 0xFF
        #     if key == ord(' ') or key == ord('q'):
        #         break
        if args.show is True:
            print("args.show is True")

            # è®¾ç½®ç›®æ ‡åˆ†è¾¨ç‡ï¼Œä¾‹å¦‚ 1280x720
            width, height = 1080, 640
            img_resized = cv2.resize(img, (width, height))  # è°ƒæ•´åˆ†è¾¨ç‡

            cv2.imshow('BoxMOT', img_resized)  # æ˜¾ç¤ºè°ƒæ•´åçš„å›¾åƒ
            key = cv2.waitKey(1) & 0xFF
            if key == ord(' ') or key == ord('q'):
                break


def parse_opt():
    parser = argparse.ArgumentParser()

    # æ£€æµ‹æ¨¡å‹åŠå…¶æƒé‡æ–‡ä»¶
    parser.add_argument('--yolo-model', type=Path, default=WEIGHTS / 'yolov8n_QCow.pt', help='yolo model path')

    # ReIDæ¨¡å‹åŠå…¶æƒé‡æ–‡ä»¶
    parser.add_argument('--reid-model', type=Path, default=WEIGHTS / 'osnet_x0_25_selfCowData.pth', help='reid model path')

    # è·Ÿè¸ªæ–¹æ³•ï¼ˆeepocsort, botsort, strongsort, ocsort, bytetrack, imprassocï¼‰
    parser.add_argument('--tracking-method', type=str, default='botsort',
                        help='deepocsort, botsort, strongsort, ocsort, bytetrack, imprassoc')
    # è·Ÿè¸ªæ•°æ® æ–‡ä»¶ä½ç½®
    parser.add_argument('--source', type=str, default=r'/media/v10016/å®éªŒå®¤å¤‡ä»½/XingshiXu/boxmot-master/CowMulDataFPS5/20240425_10_01_D3_fps5.mp4', help='file/dir/URL/glob, 0 for webcam')



    # å›¾åƒå°ºå¯¸å¤§å°
    parser.add_argument('--imgsz', '--img', '--img-size', nargs='+', type=int, default=[640],
                        help='inference size h,w')

    parser.add_argument('--conf', type=float, default=0.5,
                        help='confidence threshold')
    parser.add_argument('--iou', type=float, default=0.7,
                        help='intersection over union (IoU) threshold for NMS')
    parser.add_argument('--device', default='',
                        help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    # æ˜¯å¦è§†é¢‘show
    parser.add_argument('--show', default=True, action='store_true',
                        help='display tracking video results')
    # æ˜¯å¦ä¿å­˜è·Ÿè¸ªç»“æœ
    parser.add_argument('--save', default=True, action='store_true',
                        help='save video tracking results')
    # class 0 is person, 1 is bycicle, 2 is car... 79 is oven
    parser.add_argument('--classes', nargs='+', type=int,
                        help='filter by class: --classes 0, or --classes 0 2 3')

    ##### ç»“æœä¿å­˜ #####
    parser.add_argument('--project', default=ROOT / 'runs' / 'track_LunWen',
                        help='save results to project/name')
    parser.add_argument('--name', default='exppPP',
                        help='save results to project/name')


    parser.add_argument('--exist-ok', action='store_true',
                        help='existing project/name ok, do not increment')
    parser.add_argument('--half', action='store_true',
                        help='use FP16 half-precision inference')
    parser.add_argument('--vid-stride', type=int, default=1,
                        help='video frame-rate stride')
    parser.add_argument('--show-labels', action='store_false',
                        help='either show all or only bboxes')
    parser.add_argument('--show-conf', default=False, action='store_false',
                        help='hide confidences when show')
    parser.add_argument('--show-trajectories', default=True,action='store_true',
                        help='show confidences')
    parser.add_argument('--save-txt', action='store_true',
                        help='save tracking results in a txt file')
    parser.add_argument('--save-id-crops', action='store_true',
                        help='save each crop to its respective id folder')
    parser.add_argument('--line-width', default=None, type=int,
                        help='The line width of the bounding boxes. If None, it is scaled to the image size.')
    parser.add_argument('--per-class', default=False, action='store_true',
                        help='not mix up classes when tracking')
    parser.add_argument('--verbose', default=True, action='store_true',
                        help='print results per frame')
    parser.add_argument('--agnostic-nms', default=False, action='store_true',
                        help='class-agnostic NMS')

    opt = parser.parse_args()
    return opt


if __name__ == "__main__":
    opt = parse_opt()
    run(opt)
